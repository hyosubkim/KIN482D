{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2eff6d-a394-4ad9-a3ba-9541af75ff8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# KIN 482D: Computational modeling of human sensorimotor control and learning\n",
    "\n",
    "## Chapter 5: Cue combination and evidence accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcff26-e4f6-496c-9a02-73efd25cc3cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Housekeeping\n",
    "\n",
    "- Come hear a [talk on Bayesian statistics](https://greencollege.ubc.ca/civicrm/event/info%3Fid%3D1814%26reset%3D1) this Wednesday, 5-6:30pm, at Green College\n",
    "    - Prof. Paul Gustafson, Head of Department of Statistics @ UBC\n",
    "    - You will be rewarded for attending\n",
    "- Bring your questions to class on Wednesday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746374b7-3f2d-4892-83dc-d24720f6b228",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Big question of this chapter\n",
    "\n",
    "*How can we integrate multiple sensory inputs (\"cues\") into a single percept?*\n",
    "\n",
    "This is the fundamental question underlying multisensory integration. \n",
    "\n",
    "Real world examples: \n",
    "- Localizing limb position given visual and proprioceptive cues\n",
    "- Localizing a bouncing basketball given visual and auditory cues\n",
    "- Intepreting where a conversation is coming from through visual and auditory cues from your TV\n",
    "- Identifying a food from its smell and taste\n",
    "- Estimating our acceleration in a moving vehicle can involve vision, proprioception, and our vestibular sense\n",
    "- Non-multisensory integration example involving cue combination: In vision we use color, texture, and depth to identify an object\n",
    "- The point is that it's everywhere and happening virtually all of the time\n",
    "\n",
    "<center><img src=\"images/bounce-pass.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b7941-26ff-45fd-a7d6-4f6aaf771d55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan\n",
    "\n",
    "- Discuss intuitions behind cue combination\n",
    "- Develop Steps 1 through 3 of Bayesian inference for cue combination\n",
    "- Show how integration of sensory evidence over time is mathematically equivalent to cue combination\n",
    "- Discuss empirical literature on humans using cue combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71077e7e-f65a-426e-836a-c338863450ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why combine cues? Or, why not just go with the most reliable cue? \n",
    "\n",
    "- Even our most reliable sense vision has uncertainty associated with it\n",
    "- Paying attention to only the most reliable cue (\"Winner-take-all\" model) means ignoring a cue, which is akin to discarding useful information \n",
    "- The best strategy is to combine all possible sources of information in an optimal manner (which we'll specify in a bit) - this will lead to more precise estimates\n",
    "- Combining cues can also resolve ambiguities \n",
    "    - Inferring an object's identity by shape alone may be difficult because many different objects may have similar shapes \n",
    "    - A spherical object is consistent with peaches and oranges\n",
    "    - Proprioception can tell us about the shape, while mechanoreceptors can tell us about texture\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f490d05-6663-44e7-9da5-05e0df1897b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/fig5-1.png\" width=600></center>\n",
    "\n",
    "Speaker produces brief auditory tone at the same time an LED lights up. Subject uses a laser pointer to indicate the perceived position of the tone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132026d-8c87-4a67-99ee-5c588096f8bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1: The graphical generative model\n",
    "<center><img src=\"images/fig5-2.png\" width=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e0cbc4-73b9-44ce-9dd7-cdd76d5cce27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional independence\n",
    "\n",
    "- The auditory and visual measurements are independent of each other *when conditioned on the true stimulus*. We can't say they are independent of each other because when the auditory measurement is left, the visual measurement will tend to be left as well (and vice versa). However, we assume that on repeated presentations of the *same stimulus*, the trial-by-trial variability in the auditory and visual measurements will be uncorrelated. \n",
    "\n",
    "- Mathematically: \n",
    "\n",
    "\\begin{align}\n",
    "p(x_1, x_2|s) &= p(x_1|x_2, s)p(x_2|s) = p(x_2|x_1, s)p(x_1|s) \\space [\\text{General axiom of probability theory.}] \\\\\n",
    "              &= p(x_1|s)p(x_2|s) \\space [\\text{Only if conditionally independent.}] \\\\\n",
    "p(x_1, x_2)   &= p(x_1)p(x_2) \\space [\\text{Only if truly independent.}]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "**Possible board time for Box 5.1.**\n",
    "\n",
    "- Conditional independence occurs when 2 RVs are independent only given the value of a third RV.\n",
    "- Examples: \n",
    "    - Having Alzheimer's and needing reading glasses are not independent because they both occur more frequently in elderly. However, among only 80-year olds (i.e., given the age group), the two are probably more or less independent. \n",
    "    - Homicide rates and ice cream sales are correlated; however, they are independent when given (conditioned on) temperature\n",
    "- Intuition is that you condition on the value of the cause of dependence of the two variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa6d00-89cb-4734-9e64-e2889b92c9c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Inference\n",
    "\n",
    "**Go to the board.**\n",
    "\n",
    "Making use of the structure of the generative model to express the likelihood in terms of elementary likelihoods is the only new concept compared to the noisy measurement model of chapter 3. \n",
    "\n",
    "Posterior variance is less than variance of either likelihood. Prove.\n",
    "\n",
    "With a flat prior in this case, the PME, MAP, *and* MLE are all the same! **Think:** Why is it the MLE as well? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b2f20-5e93-4971-b6cb-7b91f53b2b23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/fig5-3.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d09f8f-7605-4dfd-a2ce-643df135371c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Estimate distribution\n",
    "\n",
    "Assuming a flat prior in cue combination:\n",
    "\n",
    "- The PME is equal to $s$. Prove. (Easy)\n",
    "- The variance of the estimate distribution is equal to $\\dfrac{1}{J_1 + J_2}$. Prove (think linear combination of RVs). In other words, it's the same as the posterior variance we learned about for combining Gaussian prior and likelihood and *not* the same as the estimate distribution from Chapter 4 (i.e., $\\dfrac{J}{(J + J_s)^2}$), correct? \n",
    "\n",
    "**Board time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe322177-befe-4099-8134-3955ae42f2ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.3 Artificial Cue Conflict\n",
    "\n",
    "- Since the PME is on average equal to the true stimulus, it is difficult to distinguish between the Bayesian cue combination model and another model in which the observer uses only one cue\n",
    "    - Of course, the variance across responses would help distinguish (*why?*) but it's better to have multiple discriminating points\n",
    "- In cue combination experiments, a common trick is to \"secretly\" introduce a conflict between the true stimuli in the two modalities&mdash;instead of just $s$, we now have $s_1$ and $s_2$\n",
    "    - **Caveat:** For this to work, subject still needs to believe the measurements are coming from a single $s$\n",
    "    \n",
    "<center><img src=\"images/ernst-and-banks-fig2.png\" width=500></center>\n",
    "\n",
    "*Fig. 2a from Ernst and Banks (2002)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33580ad6-8429-4365-8473-3c99f629fee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.3: Artificial cue conflict\n",
    "\n",
    "- Including discrepancy between two cues allows for easy test of whether human behavior conforms with Bayesian cue combination prediction or winner-take-all type of model\n",
    "- Why isn't the observer's inference of a single $s$ considered suboptimal? \n",
    "    - Even when there is truly a single $s$, the measurements from each modality will very frequently be different (why?)\n",
    "    - Consider this a situation where observer is utlizing a prior based on natural statistics (e.g., when observers sees a ball hit the ground and hears a thud at same moment, nearly always coming from same event/location)\n",
    "- Cue combination model only considers situations where discrepancies between cues are small enough for observer to believe - cue combination is a special case of a more general model (\"causal inference\" model; Ch 10)\n",
    "\n",
    "**Board time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e950cf-114a-4b68-8911-371aeb1f1cea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributions covered in this chapter\n",
    "\n",
    "<img src=\"images/table5-1.png\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3588ff6-49ea-4f13-8dd6-a002d5bad5ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.4 Generalizations: Prior, Multiple Cues\n",
    "\n",
    "<center><img src=\"images/fig5-4.png\" width=500></center>\n",
    "\n",
    "**Board.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a4afb-c759-42aa-9f09-ef44bc074180",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Housekeeping (Wed, Feb 14, 2024)\n",
    "\n",
    "- Reminder to start thinking about Final Projects -- I will start meeting with you individually after Reading Week\n",
    "- Problem Set 5\n",
    "    - 5.5: only need to answer a - c; (b) Answer does not need to include $\\mu$\n",
    "    - 5.6: part (d) - \n",
    "- Finish Chapter 5 material today\n",
    "- Problem Sets 3-4\n",
    "- Discuss Ernst & Banks\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f9276-81c9-46ef-b8a4-2c2f3120546a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.5 Evidence Accumulation\n",
    "\n",
    "**Start at board.**\n",
    "\n",
    "- Multiple cues get replaced with measurements at multiple time points\n",
    "- Bayesian updating of the posterior means using posterior at time $t$ as prior for time $t + 1$. \n",
    "- Several important caveats (read over on your own--ask questions at next class, if you have them)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb3cf9-2467-420f-84e9-b66da47639d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- Cue combination is a frequent and important perceptual activity that often happens automatically\n",
    "and outside of our conscious control.\n",
    "- Just like when combining a prior with a likelihood, all the Bayesian observer needs to do is\n",
    "multiply two probability distributions and normalize.\n",
    "- Unlike the winner-take-all strategy, the optimal Bayesian solution (posterior mean estimate)\n",
    "is to weight each cue according to its reliability.\n",
    "- The Bayesian model accounts for human data in a wide variety of settings.\n",
    "- Cue combination illustrates that prior can be flat in an interesting Bayesian model.\n",
    "- Cue combination can take place over time, in which case it is sometimes called evidence\n",
    "accumulation, evidence integration, or decision-making. Across subsequent measurements,\n",
    "uncertainty is reduced. The PME is a linear combination of the individual measurements,\n",
    "weighted by their precisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c7706",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## For next class\n",
    "\n",
    "- Bring questions (next problem set will be posted tonight)\n",
    "- Review problem sets 3-4\n",
    "- Recommended reading: Ernst & Banks article (Nature, 2002); classic paper"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
